{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "creditscore.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hGuTlGBywG3",
        "colab_type": "text"
      },
      "source": [
        "**This credit score predictor uses Kaggle's \"give me some credit dataset\" for predicting the credit score of the client**\n",
        "**the predictor calculates what is the chance of the client actually returning the loan given to them,or whether the client will face some kind of financial crisis and won't be able to return the loan**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in9vrQoaz9tS",
        "colab_type": "text"
      },
      "source": [
        "the first cell is mainly removing the the rows in the training data which contain any feature with NULL in it. as they may disturb the training of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLyaqytZNW4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline \n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"cs-test.csv\")\n",
        "\n",
        "# Dropping the first unnamed column\n",
        "data = data.drop(['id'], axis = 1)\n",
        "\n",
        "#display the first 5 records\n",
        "display(data.head(5))\n",
        "\n",
        "#removing all the rows with null entries in them \n",
        "x=data\n",
        "ind=x[x['MonthlyIncome'].isnull()].index.tolist()\n",
        "x.drop(x.index[[ind]], inplace=True)\n",
        "print('indexes')\n",
        "print(x[x['MonthlyIncome'].isnull()].index.tolist())\n",
        "print(x[x['NumberOfDependents'].isnull()].index.tolist())\n",
        "x.to_csv('test.csv',index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riNoDG7s0dMm",
        "colab_type": "text"
      },
      "source": [
        "the second cell is dividing the training data into features and label file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq_GBd-fOJ1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "j=[]\n",
        "pro=open('feature.csv','a')\n",
        "with open('x.csv', 'r') as csvfile: \n",
        "    # creating a csv reader object \n",
        "    csvreader = csv.reader(csvfile ,delimiter=',')\n",
        "    print(csvreader)\n",
        "    for row in csvreader:\n",
        "        \n",
        "        for i in row[1:]:\n",
        "            pro.write(i+\",\")\n",
        "        pro.write(\"\\n\")    \n",
        "    pro.close()\n",
        "\n",
        "j=[]\n",
        "pro=open('label.csv','a')\n",
        "with open('x.csv', 'r') as csvfile: \n",
        "    # creating a csv reader object \n",
        "    csvreader = csv.reader(csvfile ,delimiter=',')\n",
        "    print(csvreader)\n",
        "    for row in csvreader:\n",
        "        pro.write(row[0])\n",
        "        pro.write(\"\\n\")    \n",
        "    pro.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wXDdRh10w36",
        "colab_type": "text"
      },
      "source": [
        "this cell is converting the features and label file into numpy arrays and dividing the data into training and test sets,and then scalling the data for normalisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR3muwCcL1Tu",
        "colab_type": "code",
        "outputId": "cbed060a-54e8-4fb0-ffd8-78c40aed538e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "f_data_x=[]\n",
        "with open('feature.csv', 'r') as csvfile: \n",
        "    # creating a csv reader object \n",
        "    csvreader = csv.reader(csvfile ,delimiter=',')\n",
        "    print(csvreader)\n",
        "    data=list(csvreader)\n",
        "    \n",
        "    for i in data:\n",
        "        f_data_x.append([float(k) for k in i[:-1]])\n",
        "\n",
        "        \n",
        "\n",
        "    \n",
        "f_data_y=[]\n",
        "with open('label.csv', 'r') as csvfile: \n",
        "    # creating a csv reader object \n",
        "    csvreader = csv.reader(csvfile ,delimiter=',')\n",
        "    print(csvreader)\n",
        "    data=list(csvreader)\n",
        "    \n",
        "    for i in data:\n",
        "      #print(i)\n",
        "      f_data_y.append(float(i[0]))\n",
        "f_data_x=np.array(f_data_x)\n",
        "f_data_y=np.array(f_data_y)\n",
        "f_data_x=f_data_x/f_data_x.max(axis=0)\n",
        "\n",
        "train_x=f_data_x[0:110000]\n",
        "train_y=f_data_y[0:110000]\n",
        "test_x=f_data_x[110000:len(f_data_x)]\n",
        "test_y=f_data_y[110000:len(f_data_x)]\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<_csv.reader object at 0x7f7ce57c9eb8>\n",
            "<_csv.reader object at 0x7f7ce62c7128>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBtrawgl1Ov1",
        "colab_type": "text"
      },
      "source": [
        "This cell is creating the neural network and and training it with the training data that we got after seprating the available data into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNcNbSZdLOfo",
        "colab_type": "code",
        "outputId": "d8e30a9f-ab7b-4059-9062-f0f7b1d55ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "class mycallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if logs.get('acc')>0.99:\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training=True\n",
        "      \n",
        "      \n",
        "  \n",
        "\n",
        "callback=mycallback()  \n",
        "\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10,input_shape=(10,),activation=tf.nn.relu),\n",
        "    \n",
        "    tf.keras.layers.Dense(8,activation=tf.nn.relu),\n",
        "\n",
        "    tf.keras.layers.Dense(8,activation=tf.nn.relu),\n",
        "\n",
        "    tf.keras.layers.Dense(8,activation=tf.nn.relu),\n",
        "\n",
        "    tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)\n",
        "   \n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_x,train_y,epochs=10, callbacks=[callback])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 110000 samples\n",
            "Epoch 1/10\n",
            "110000/110000 [==============================] - 14s 128us/sample - loss: 0.2490 - acc: 0.9310\n",
            "Epoch 2/10\n",
            "110000/110000 [==============================] - 16s 144us/sample - loss: 0.2046 - acc: 0.9336\n",
            "Epoch 3/10\n",
            "110000/110000 [==============================] - 15s 139us/sample - loss: 0.1998 - acc: 0.9339\n",
            "Epoch 4/10\n",
            "110000/110000 [==============================] - 15s 138us/sample - loss: 0.1987 - acc: 0.9341\n",
            "Epoch 5/10\n",
            "110000/110000 [==============================] - 15s 136us/sample - loss: 0.1981 - acc: 0.9342\n",
            "Epoch 6/10\n",
            "110000/110000 [==============================] - 15s 141us/sample - loss: 0.1978 - acc: 0.9343\n",
            "Epoch 7/10\n",
            "110000/110000 [==============================] - 15s 137us/sample - loss: 0.1977 - acc: 0.9341\n",
            "Epoch 8/10\n",
            "110000/110000 [==============================] - 16s 141us/sample - loss: 0.1974 - acc: 0.9343\n",
            "Epoch 9/10\n",
            "110000/110000 [==============================] - 15s 141us/sample - loss: 0.1974 - acc: 0.9341\n",
            "Epoch 10/10\n",
            "110000/110000 [==============================] - 15s 135us/sample - loss: 0.1974 - acc: 0.9341\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7c501542b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZHyror_1pHc",
        "colab_type": "text"
      },
      "source": [
        "Saving the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV7EnSV2kAcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"creditpredictor.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqBuuGiu1vkJ",
        "colab_type": "text"
      },
      "source": [
        "evaluating the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykhZ0WITxPd",
        "colab_type": "code",
        "outputId": "65d6c387-658d-4604-e019-62d10f2152ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10269/10269 [==============================] - 1s 72us/sample - loss: 0.2052 - acc: 0.9299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20515571967346294, 0.92988604]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RghIwmq32x3k",
        "colab_type": "text"
      },
      "source": [
        "calculating the credit score on any test example , simply specify the example number between 1 and 10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MKBCZPYhzN_",
        "colab_type": "code",
        "outputId": "5921f820-1b2c-4ede-8d2c-a8067f164806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score=model.predict(np.array([train_x[0]]))\n",
        "#print(score)\n",
        "print(\"credit score of mentioned example is\" ,1000-int(score[0][0]*1000))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "credit score of mentioned example is 799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMtFeTvlqWJ8",
        "colab_type": "code",
        "outputId": "20d1f650-6dd7-4979-beea-15f1924b6f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "newmodel=tf.keras.models.load_model(\"creditpredictor.h5\")\n",
        "score=newmodel.predict(np.array([train_x[0]]))\n",
        "#print(score)\n",
        "print(\"credit score of mentioned example is\" ,1000-int(score[0][0]*1000))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "credit score of mentioned example is 799\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}